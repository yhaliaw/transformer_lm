# transformer_lm
Implementations of various transformer-based language models.

The transformer models and components are implemented using PyTorch. 
Supports a wide variety of features such as, floating point 16 training, many learning rate schedules, adaptive input, adaptive softmax, etc.
